<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Dual Mouse Odometry</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Joshua Vasquez">

    <!-- Le styles -->
    <link href="../../assets/css/bootstrap-custom.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
      }
    </style>
    <link href="../../assets/css/bootstrap-responsive.css" rel="stylesheet">


    <!-- Fav and touch icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="../../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../../assets/ico/apple-touch-icon-114-precomposed.png">
      <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../../assets/ico/apple-touch-icon-72-precomposed.png">
                    <link rel="apple-touch-icon-precomposed" href="../../assets/ico/apple-touch-icon-57-precomposed.png">
                                   <link rel="shortcut icon" href="../../assets/ico/favicon.png">
    <!-- Custom Fonts -->
    <link href='http://fonts.googleapis.com/css?family=Days+One|Titillium+Web' rel='stylesheet' type='text/css'>

  </head>

   <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../../../index.html">JoshuaVasquez</a>
        </div>
      </div>
    </div>


<body data-spy="scroll" data-target=".bs-docs-sidebar">


<div class="span2 bs-docs-sidebar">
<ul class="nav nav-list bs-docs-sidenav affix">
          <li><a href="#Introduction"><i class="icon-chevron-right"></i>Introduction</a></li>
          <li><a href="#BackgroundTheory"><i class="icon-chevron-right"></i>Background Theory</a></li>
          <li><a href="#InitialImplementation"><i class="icon-chevron-right"></i>Initial Implementation</a></li>
          <li><a href="#Resources"><i class="icon-chevron-right"></i>Resources</a></li>
        </ul>
</div>


<div class="span9">


<h4 align="right">
Joshua Vasquez and Lauren Lieu 
</h4>

<h4 align="right">
<i>E190: Autonomous Robot Navigation</i> Final Project
</h4>

      <h1 style="text-align: center;">Dual Optical Mouse Odometry</h1>
<center>
<img src="../../assets/img/Projects/OpticalMouseOdometry/IntroPic.jpg" width=600>
<h3 style="text-align: center;">
<i>tracking location with optical flow sensors </i>
</h3>
</center>


<section id="Introduction">

<div class="page-header">
<h2> Introduction</h2>
</div>

<p>
    For wheeled robots, traditional odometry typically relies on leveraging encoders on the 
wheels of the robotâ€™s drive train.  While rotations can be transformed into displacement with 
a motion model, this method of odometry leads to the buildup of error. We propose an 
alternative motion model using two optical mice as inputs, rather than two wheel encoders.  
Initially, both mice will be placed flush with the ground; however, given time after implementing
 the motion model, we plan to add new optical lenses to the mouse inputs such that both mice 
need not be flush with the ground.
</p>
</section>



<section id="BackgroundTheory">
<div class="page-header">
<h2>Background Theory</h2>
<h3> The Mouse Sensor </h3>
    At the core of optical mouse hardware is a high-speed, low-resolution camera, likely a chip made by
<a href='http://www.avagotech.com/pages/en/navigation_interface_devices/navigation_sensors/led-based_sensors/' >Avago Technologies</a>.
Through optical flow, an
algorithm implemented on the mouse IC chip tracks features in the camera image and outputs a deltaX and a deltaY 
value since it was last queried.  By bringing this data from two mice into the computer via usb, a software-implemented 
motion model can estimate the displacement of the robot since startup.  This method of deducing location, while free 
from wheel slip from encoder odometry, must keep the image in the  optical sensor at a relatively constant distance to 
the ground.  Furthermore, with the existing startup hardware, the mouse can only track speeds up to 40 [in/sec].  We will 
work within these constraints to form a new motion model, operating the mouse under normal operating conditions.  
</div>

<h3> The Motion Model </h3>
<p>
For this project, we've implemented the motion model described by Andrea Bonarini, Matteo Matteucci, and
Marcello Restelli in 
<a href='http://chrome.ws.dei.polimi.it/images/5/56/Bonarini_2004_ICINCO.pdf'>Dead Reckoning For Mobile Robots Using Two Optical Mice</a>.
This model uses two mice offset by a distance <i>D</i> to compute the pose <i> (x, y, &theta;)</i> from 
the raw (&Delta;X<sub>1</sub>, &Delta;Y<sub>1</sub>, &Delta;X<sub>2</sub>, &Delta;Y<sub>2</sub>) 
values given by the two mice at each time step. The result is similar to the 
<a href='http://www.cs.columbia.edu/~allen/F11/NOTES/icckinematics.pdf'>motion model</a> given by 
wheel encoders on a differential drive robot.
</p>

<section id="InitialImplementation">

<div class="page-header">
<h2>Initial Implementation</h2>
<h3> The Hardware Platform </h3>
<p>
Our hardware platform of choice (our class robot), is a Jaguar Lite, sourced by Dr. Robot. This differential-
drive platform is fairly rugged, and it features a suite of sensory
inputs: a 9-DOF Inertial measurement unit (IMU), two rotary
encoders, a laser range finder, and an on-
board webcam [2]. With a wireless wifi interface, we
can implement navigation algorithms in C# within Microsoft
Visual Studio to communicate with the Jaguar platform. 
</p>
<p>
<h3> Hardware Hacking </h3>
To add our two mice to the sensory inputs, we had to make some slight hardware modifications.
Since the C# suite of tools didn't have a simple implementation for accepting two mouse inputs, 
we settled for the next best solution: building a custom sensor to integrate into the 
Jaguar's suite of sensors. 
</p>
Our overall block diagram is displayed below:
<center>
<img src="../../assets/img/Projects/OpticalMouseOdometry/Picture2.png" width=600>
</center>


<p>
To tackle this challenge, we combined the 
<a href='https://icculus.org/manymouse/'>manymouse</a> library with Gordon's  
<a href='https://projects.drogon.net/raspberry-pi/wiringpi/serial-library/'>wiringPi</a> 
library as well as a few snippets of our own code to snag the movement events from both mice and 
output their data over the harware serial port.

By removing the existing IMU, a serial device, from the serial port, and replacing it with our new
Raspberry Pi <i>dual mouse sensor </i>, we were able to bring the mouse data into C# as a false 
imu sensor, provided that we mimicked the IMU data packet and filled it with our own data.
<center>
<img src="../../assets/img/Projects/OpticalMouseOdometry/blockDiagram.png" width=600>
</center>
</p>

<h3> Results </h3>
<p>
In the brief clip below, we can see the onscreen robot tracking the two mice on the wooden table.
</p>

<div class="embed-container">
 <iframe src="http://youtu.be/Vd8OnHY5K3Q"; frameborder="0"> </iframe>
</div>


</div>



<section id="Resources">
<div class="page-header">
<h2>Resources</h2>
<p>
<a href='http://botsnlinux.net/school_projects/mouse_paper_colloquium_22march11.pdf'>High-Precision Robot Odometry Using an Array of Optical Mice</a>
<br>
This paper describes a clever model that, with least-squares fitting theoretically,
 gets more accurate odometry data by increasing the number of mice that are used for odometry.  
</p>

<p>
<a href='http://chrome.ws.dei.polimi.it/images/5/56/Bonarini_2004_ICINCO.pdf'>Dead Reckoning For Mobile Robots Using Two Optical Mice</a>
<br>
This paper contains the motion model that we did implement using our two mice offset by the distance <i>D</i>.
</p>


<p>
</p>
</div>



</div>

    <div class="container">
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/js/jquery.js"></script>
    <script src="../assets/js/bootstrap-transition.js"></script>
    <script src="../assets/js/bootstrap-alert.js"></script>
    <script src="../assets/js/bootstrap-modal.js"></script>
    <script src="../assets/js/bootstrap-dropdown.js"></script>
    <script src="../assets/js/bootstrap-scrollspy.js"></script>
    <script src="../assets/js/bootstrap-tab.js"></script>
    <script src="../assets/js/bootstrap-tooltip.js"></script>
    <script src="../assets/js/bootstrap-popover.js"></script>
    <script src="../assets/js/bootstrap-button.js"></script>
    <script src="../assets/js/bootstrap-collapse.js"></script>
    <script src="../assets/js/bootstrap-carousel.js"></script>
    <script src="../assets/js/bootstrap-typeahead.js"></script>

  </body>
</html>
